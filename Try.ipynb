{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:15:30.202437Z",
     "start_time": "2024-12-16T16:15:29.835376Z"
    }
   },
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, FunctionTransformer, LabelBinarizer,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import dump\n",
    "\n",
    "# Data loading (use your path)\n",
    "path = \"bank-additional/bank-additional.csv\"\n",
    "bank = pd.read_csv(path, sep=';')\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:15:30.614289Z",
     "start_time": "2024-12-16T16:15:30.597904Z"
    }
   },
   "cell_type": "code",
   "source": "bank.head()",
   "id": "8594ff8f79a3c118",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:15:32.076893Z",
     "start_time": "2024-12-16T16:15:32.069738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We get all numeric features as a list\n",
    "numeric_features_add = bank.select_dtypes(include = 'number').columns.tolist()\n",
    "print(numeric_features_add)\n",
    "\n",
    "#We get all categorical features as a list\n",
    "categorical_features_add = bank.select_dtypes(include = 'object').columns.tolist()\n",
    "categorical_features_add.remove(\"y\")\n",
    "print(categorical_features_add)\n",
    "\n",
    "#So we can see that only categorical features has nulls\n",
    "null_columns_add = bank.columns[bank.isnull().any()].tolist()\n",
    "print(null_columns_add)"
   ],
   "id": "73372827c3899b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
      "[]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:46:34.798314Z",
     "start_time": "2024-12-08T21:46:34.769964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Cyclic encoding for month\n",
    "month_mapping = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "                 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "bank['month'] = bank['month'].map(month_mapping)\n",
    "bank['month_sin'] = np.sin(2 * np.pi * bank['month'] / 12)\n",
    "bank['month_cos'] = np.cos(2 * np.pi * bank['month'] / 12)\n",
    "bank.drop('month', axis=1, inplace=True)\n",
    "\n",
    "# Cyclic encoding for day_of_week\n",
    "\"\"\"\n",
    "day_of_week_mapping = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5}\n",
    "bank['day_of_week'] = bank['day_of_week'].map(day_of_week_mapping)\n",
    "bank['day_of_week_sin'] = np.sin(2 * np.pi * bank['day_of_week'] / 5)\n",
    "bank['day_of_week_cos'] = np.cos(2 * np.pi * bank['day_of_week'] / 5)\n",
    "bank.drop('day_of_week', axis=1, inplace=True)\n",
    "\"\"\"\n",
    "bank = pd.get_dummies(bank, columns=['day_of_week'], prefix='day_of_week')\n",
    "\n",
    "# Ordinal encoding for education\n",
    "education_mapping = [['illiterate', 'unknown', 'basic.4y', 'basic.6y', 'basic.9y',\n",
    "                    'high.school', 'university.degree', 'professional.course']]\n",
    "education_encoder = OrdinalEncoder(categories=education_mapping)\n",
    "bank['education'] = education_encoder.fit_transform(bank[['education']])\n",
    "\n",
    "# Ordinal encoding for default, housing, and loan\n",
    "has_loan_order = [['no', 'unknown', 'yes']]\n",
    "loan_encoder = OrdinalEncoder(categories=has_loan_order * 3)  # Repeat for three columns\n",
    "bank[['default', 'housing', 'loan']] = loan_encoder.fit_transform(bank[['default', 'housing', 'loan']])\n",
    "\n",
    "# Ordinal encoding for poutcome\n",
    "poutcome_mapping = [['failure', 'nonexistent', 'success']]  # Ordered: worst to best\n",
    "poutcome_encoder = OrdinalEncoder(categories=poutcome_mapping)\n",
    "bank['poutcome'] = poutcome_encoder.fit_transform(bank[['poutcome']])\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_data = encoder.fit_transform(bank[['contact', 'job', 'marital']])\n",
    "# Convert the encoded data to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenate the encoded DataFrame with the original DataFrame\n",
    "bank = pd.concat([bank.drop(['contact', 'job', 'marital'], axis=1), encoded_df], axis=1)\n"
   ],
   "id": "12b9f09b28f708b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:46:39.946206Z",
     "start_time": "2024-12-08T21:46:39.929791Z"
    }
   },
   "cell_type": "code",
   "source": "bank.head()",
   "id": "95fbb273fba368af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  education  default  housing  loan  duration  campaign  pdays  \\\n",
       "0   30        4.0      0.0      2.0   0.0       487         2    999   \n",
       "1   39        5.0      0.0      0.0   0.0       346         4    999   \n",
       "2   25        5.0      0.0      2.0   0.0       227         1    999   \n",
       "3   38        4.0      0.0      1.0   1.0        17         3    999   \n",
       "4   47        6.0      0.0      2.0   0.0        58         1    999   \n",
       "\n",
       "   previous  poutcome  ...  job_self-employed  job_services  job_student  \\\n",
       "0         0       1.0  ...                0.0           0.0          0.0   \n",
       "1         0       1.0  ...                0.0           1.0          0.0   \n",
       "2         0       1.0  ...                0.0           1.0          0.0   \n",
       "3         0       1.0  ...                0.0           1.0          0.0   \n",
       "4         0       1.0  ...                0.0           0.0          0.0   \n",
       "\n",
       "   job_technician  job_unemployed job_unknown  marital_divorced  \\\n",
       "0             0.0             0.0         0.0               0.0   \n",
       "1             0.0             0.0         0.0               0.0   \n",
       "2             0.0             0.0         0.0               0.0   \n",
       "3             0.0             0.0         0.0               0.0   \n",
       "4             0.0             0.0         0.0               0.0   \n",
       "\n",
       "   marital_married  marital_single  marital_unknown  \n",
       "0              1.0             0.0              0.0  \n",
       "1              0.0             1.0              0.0  \n",
       "2              1.0             0.0              0.0  \n",
       "3              1.0             0.0              0.0  \n",
       "4              1.0             0.0              0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>...</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:15:42.161579Z",
     "start_time": "2024-12-16T16:15:42.154761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def preprocess_bank_data(bank):\n",
    "    # Cyclic encoding for month\n",
    "    month_mapping = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "                     'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "    bank['month'] = bank['month'].map(month_mapping)\n",
    "    bank['month_sin'] = np.sin(2 * np.pi * bank['month'] / 12)\n",
    "    bank['month_cos'] = np.cos(2 * np.pi * bank['month'] / 12)\n",
    "    bank.drop('month', axis=1, inplace=True)\n",
    "\n",
    "    # Cyclic encoding for day_of_week\n",
    "    \"\"\"\n",
    "    day_of_week_mapping = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5}\n",
    "    bank['day_of_week'] = bank['day_of_week'].map(day_of_week_mapping)\n",
    "    bank['day_of_week_sin'] = np.sin(2 * np.pi * bank['day_of_week'] / 5)\n",
    "    bank['day_of_week_cos'] = np.cos(2 * np.pi * bank['day_of_week'] / 5)\n",
    "    bank.drop('day_of_week', axis=1, inplace=True)\n",
    "    \"\"\"\n",
    "    bank = pd.get_dummies(bank, columns=['day_of_week'], prefix='day_of_week')\n",
    "\n",
    "    # Ordinal encoding for education\n",
    "    education_mapping = [['illiterate', 'unknown', 'basic.4y', 'basic.6y', 'basic.9y',\n",
    "                        'high.school', 'university.degree', 'professional.course']]\n",
    "    education_encoder = OrdinalEncoder(categories=education_mapping)\n",
    "    bank['education'] = education_encoder.fit_transform(bank[['education']])\n",
    "\n",
    "    # Ordinal encoding for default, housing, and loan\n",
    "    has_loan_order = [['no', 'unknown', 'yes']]\n",
    "    loan_encoder = OrdinalEncoder(categories=has_loan_order * 3)  # Repeat for three columns\n",
    "    bank[['default', 'housing', 'loan']] = loan_encoder.fit_transform(bank[['default', 'housing', 'loan']])\n",
    "\n",
    "    # Ordinal encoding for poutcome\n",
    "    poutcome_mapping = [['failure', 'nonexistent', 'success']]  # Ordered: worst to best\n",
    "    poutcome_encoder = OrdinalEncoder(categories=poutcome_mapping)\n",
    "    bank['poutcome'] = poutcome_encoder.fit_transform(bank[['poutcome']])\n",
    "\n",
    "    # Create a OneHotEncoder instance\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Fit and transform the categorical columns\n",
    "    encoded_data = encoder.fit_transform(bank[['contact', 'job', 'marital']])\n",
    "    # Convert the encoded data to a DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    bank = pd.concat([bank.drop(['contact', 'job', 'marital'], axis=1), encoded_df], axis=1)\n",
    "\n",
    "    return bank\n"
   ],
   "id": "a0d93af82dd3b554",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:15:46.347349Z",
     "start_time": "2024-12-16T16:15:43.863044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract target and features\n",
    "a = bank.drop(['y'], axis=1)\n",
    "b = bank['y'].map({'no': 0, 'yes': 1})  # Convert 'y' to binary\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply Preprocessing Encoding\n",
    "        ('cyclic', FunctionTransformer(preprocess_bank_data, validate=False),\n",
    "         ['month','day_of_week','education','poutcome','default', 'housing', 'loan']),\n",
    "\n",
    "        # Apply OneHotEncoder for categorical columns\n",
    "        (\"ohe\", OneHotEncoder(drop='first'), ['contact', 'job', 'marital']),\n",
    "\n",
    "        # Scale numerical features\n",
    "        ('num_scaler', StandardScaler(), numeric_features_add)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming you have your data in a DataFrame named 'X'\n",
    "bank = preprocessor.fit_transform(a)"
   ],
   "id": "3cda525c9bfcf00a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['contact', 'job', 'marital'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 23\u001B[0m\n\u001B[0;32m      7\u001B[0m preprocessor \u001B[38;5;241m=\u001B[39m ColumnTransformer(\n\u001B[0;32m      8\u001B[0m     transformers\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;66;03m# Apply Preprocessing Encoding\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     18\u001B[0m     ]\n\u001B[0;32m     19\u001B[0m )\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Assuming you have your data in a DataFrame named 'X'\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m bank \u001B[38;5;241m=\u001B[39m preprocessor\u001B[38;5;241m.\u001B[39mfit_transform(a)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    319\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:976\u001B[0m, in \u001B[0;36mColumnTransformer.fit_transform\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    974\u001B[0m     routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_empty_routing()\n\u001B[1;32m--> 976\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_func_on_transformers(\n\u001B[0;32m    977\u001B[0m     X,\n\u001B[0;32m    978\u001B[0m     y,\n\u001B[0;32m    979\u001B[0m     _fit_transform_one,\n\u001B[0;32m    980\u001B[0m     column_as_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    981\u001B[0m     routed_params\u001B[38;5;241m=\u001B[39mrouted_params,\n\u001B[0;32m    982\u001B[0m )\n\u001B[0;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result:\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fitted_transformers([])\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001B[0m, in \u001B[0;36mColumnTransformer._call_func_on_transformers\u001B[1;34m(self, X, y, func, column_as_labels, routed_params)\u001B[0m\n\u001B[0;32m    873\u001B[0m             extra_args \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    874\u001B[0m         jobs\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    875\u001B[0m             delayed(func)(\n\u001B[0;32m    876\u001B[0m                 transformer\u001B[38;5;241m=\u001B[39mclone(trans) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted \u001B[38;5;28;01melse\u001B[39;00m trans,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    882\u001B[0m             )\n\u001B[0;32m    883\u001B[0m         )\n\u001B[1;32m--> 885\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)(jobs)\n\u001B[0;32m    887\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    888\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    134\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001B[0m\n\u001B[0;32m   1308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[0;32m   1309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1310\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit_transform(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\n\u001B[0;32m   1311\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1312\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[0;32m   1313\u001B[0m             X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[0;32m   1314\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    319\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m   1083\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1084\u001B[0m             (\n\u001B[0;32m   1085\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) has a `transform`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1093\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1094\u001B[0m         )\n\u001B[0;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1097\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    319\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:252\u001B[0m, in \u001B[0;36mFunctionTransformer.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Transform X using the forward function.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \n\u001B[0;32m    240\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;124;03m    Transformed input.\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    251\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_input(X, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 252\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform(X, func\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, kw_args\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkw_args)\n\u001B[0;32m    253\u001B[0m output_config \u001B[38;5;241m=\u001B[39m _get_output_config(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdense\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(out, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names_out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;66;03m# check the consistency between the column provided by `transform` and\u001B[39;00m\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;66;03m# the the column names provided by `get_feature_names_out`.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:379\u001B[0m, in \u001B[0;36mFunctionTransformer._transform\u001B[1;34m(self, X, func, kw_args)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    377\u001B[0m     func \u001B[38;5;241m=\u001B[39m _identity\n\u001B[1;32m--> 379\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(kw_args \u001B[38;5;28;01mif\u001B[39;00m kw_args \u001B[38;5;28;01melse\u001B[39;00m {}))\n",
      "Cell \u001B[1;32mIn[4], line 40\u001B[0m, in \u001B[0;36mpreprocess_bank_data\u001B[1;34m(bank)\u001B[0m\n\u001B[0;32m     37\u001B[0m encoder \u001B[38;5;241m=\u001B[39m OneHotEncoder(sparse_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Fit and transform the categorical columns\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m encoded_data \u001B[38;5;241m=\u001B[39m encoder\u001B[38;5;241m.\u001B[39mfit_transform(bank[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontact\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjob\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmarital\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Convert the encoded data to a DataFrame\u001B[39;00m\n\u001B[0;32m     42\u001B[0m encoded_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(encoded_data, columns\u001B[38;5;241m=\u001B[39mencoder\u001B[38;5;241m.\u001B[39mget_feature_names_out())\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   4107\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 4108\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39m_get_indexer_strict(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   4110\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nmissing:\n\u001B[0;32m   6248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m nmissing \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(indexer):\n\u001B[1;32m-> 6249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m     not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   6252\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['contact', 'job', 'marital'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract target and features\n",
    "X = bank.drop(['y'], axis=1)\n",
    "y = bank['y'].map({'no': 0, 'yes': 1})  # Convert 'y' to binary\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# Resample training data to handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply Preprocessing Encoding\n",
    "        ('cyclic', FunctionTransformer(preprocess_bank_data, validate=False),\n",
    "         ['month','day_of_week','education','poutcome','default', 'housing', 'loan']),\n",
    "\n",
    "        # Apply OneHotEncoder for categorical columns\n",
    "        (\"ohe\", OneHotEncoder(drop='first'), ['contact', 'job', 'marital']),\n",
    "\n",
    "        # Scale numerical features\n",
    "        ('num_scaler', StandardScaler(), numeric_features_add)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'XGBoost': XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'MLP': MLPClassifier(max_iter=1000, random_state=42),\n",
    "    'Linear SVM': LinearSVC(max_iter=1000, random_state=42),\n",
    "    'Kernel SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'Bagging': {\n",
    "        'classifier__n_estimators': [10, 50, 100],\n",
    "        'classifier__max_samples': [0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 1]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'classifier__hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "        'classifier__activation': ['relu', 'tanh'],\n",
    "        'classifier__alpha': [0.0001, 0.001, 0.01]\n",
    "    },\n",
    "    'Linear SVM': {\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    'Kernel SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__gamma': ['scale', 0.1, 0.01]\n",
    "    }\n",
    "}\n"
   ],
   "id": "1bf2f2f15fe98b61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dictionary to store model results\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=3, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {model_results[model_name]['accuracy']}\")\n",
    "    print(f\"Recall: {model_results[model_name]['recall']}\")\n",
    "    print(f\"Precision: {model_results[model_name]['precision']}\")\n",
    "    print(f\"F1 Score: {model_results[model_name]['f1_score']}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "id": "c388a86ff7004396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Choose the best model based on F1 score\n",
    "best_model_name = max(model_results, key=lambda name: model_results[name]['f1_score'])\n",
    "best_model = model_results[best_model_name]['model']"
   ],
   "id": "224c998f03d1094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the best model\n",
    "filename = 'best_model_pipeline.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "print(\n",
    "    f\"Best model saved as {filename}: {best_model_name} with F1 score of {model_results[best_model_name]['f1_score']:.4f}\")"
   ],
   "id": "3aab5fa3c30536d4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
